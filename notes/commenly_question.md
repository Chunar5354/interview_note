# 操作系统

- brk与mmap的区别？

都是申请堆的算法，brk直接`延续`之前的堆顶向上生长，mmap会在可用内存区域中`找到一块空闲内存`

- 处理僵尸进程？

杀死父进程，僵尸进程变成`孤儿进程`，然后会被操作系统回收

- L1缓存为什么要分指令和数据？

在CPU中，取指令与取数据是不同的单元，L1进行区分后可以`减少各自的延迟`，且指令与数据可以`并行`读取，指令与数据的`替换策略`不同，可以分别处理

- 各级存储的速率

[![Wuvai4.md.png](https://z3.ax1x.com/2021/07/16/Wuvai4.md.png)](https://imgtu.com/i/Wuvai4)

CPU的周期：对于1GHz的CPU来说，一个时钟周期是`1ns`

所以可以看出，CPU内部的cache是`ns`级的

主存是`1/10μs`级的

硬盘是`ms`级的

# mysql

- 为什么要使用联合索引？

联合索引可以将多个列加入到索引中，`减少回表`

- 为什么最左前缀？

靠前的列有序可以`缩小搜索范围`

- DQL，DML，DDL，DCL

DQL（Data Query Language），主要指select

DML（Data Manage Language），主要指insert，update和delete

DDL（Data Define Language），主要指create

DCL，用于赋予或回收权限，比如grant

- 分析器负责识别表名和列名

- 优化器在有多个索引时决定使用哪个

- binlog是服务器层的日志，所有引擎都可以使用

- 为什么不要使用长事务？

在MVCC的角度，长事务会保留很旧版本的视图，导致`undo log很大`

- mysql B+树的树高？

树高受到索引大小的影响

比如8字节的bigint类型，加上6字节的指向叶子节点的指针，则每一个`非叶子节点中元素`的大小为`14字节`

而innodb默认数据页是16k，所以每个页能够存放`16384/14=1170`个非叶子元素

通常mysql数据的大小在1k左右，所以每个叶子节点能够存储16条数据

所以，高度为3的树能够存储`1170*1170*16=21902400`条数据，已经是千万级别了

所以通常mysql的B+树高在`1~3层`，进行查询时需要`1~3次IO操作`

- 索引下推

对索引中包含的字段先行判断，剔除不满足条件的记录，减少回表次数

- 锁会等到`commit`时才会释放，所以可以将占用锁的语句放到事务的末尾执行

- 死锁的两种解决策略：`超时`和`死锁检测，主动回滚`，也可以通过减少业务的`并发度`来降低死锁检测的消耗，比如相同行的更新进入存储引擎前要`排队`

- 索引选择

mysql的优化器会按照“抽样”的原理根据索引的`区分度`来为每个索引判定一个`基数`cardinality，通过`show index from t`可以查看

但是有可能会误判，选择消耗比较高的索引来执行

这种情况，可以使用`analyze table t`来优化，或者在select语句中使用`force index(i)`来指定索引，也可以修改语句，引导优化器使用其他索引

- mysql的慢操作可能是在刷脏页

刷脏页可能发生在：`redo log写满`，`内存不足`，`后台闲时刷写`，`mysql正常关闭`几种情况

刷脏页主要通过`脏页比例`（Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total）与系统`写盘速度`（innodb_io_capacity）来控制

- count()问题

对于myisam引擎，它单独存储了总行数，所以count(*)很快

对于innodb引擎，需要逐行遍历并累加，并且如果有多个索引的话，会选择最小的索引树来遍历

按照效率排序，`count(字段)< count(主键)< count(1) ≈ count(*)`

- order by问题

最好使用`覆盖索引`，或者将排序字段添加到索引中

对于全字段排序和rowid排序，使用rowid排序会`增加一次回表`，但对`内存占用更少`，实际需要权衡

对于临时文件排序，使用的是`归并排序算法`

对于limit排序，使用的是`优先队列算法`

- 使用函数时`不会用到索引`

- 将varchar类型与整数做比较时`不会用到索引`，因为mysql种字符串与整数作比较时会将字符串转换为整数

- 如果事务A在查询前事务B做了很多更新操作，事务A的快照读就需要`逐条向前查找undo log`，而如果使用当前读（lock in share mode）速度会快一些（但二者的结果不一样）

- 幻读专指`新插入的行`，因为不存在的行（即将要添加的新行）无法加锁，所以导致幻读，可以用`间隙锁`来解决

- 间隙锁之间互不冲突，间隙锁只与`往间隙中插入新纪录`这个操作冲突

- 读提交隔离级别相比于可重复读，锁的`粒度更小`（只有行锁），而且持有锁的`时间更短`（会在语句执行完后，释放不满足的行上的行锁，而可重复读要等到事务提交才会释放），所以有很多实际场景使用读提交+binlog设置为row模式

- 慢查询的可能情况

1.索引没设计好

2.sql语句没写好

3.mysql索引优化选错了索引

- mysql内置的优化重整方法

1.analyze，用于重建索引统计基数

2.recreate（alter tablt t engine = innodb)，重建表，会用到临时表，并会用一个`临时日志`存储重建期间原表的更改，所以可以online recreate

3.optimize，等于recreate + analyze

- 主备复制延迟问题

1.网络问题

2.可能备库机器的性能比主库要差

3.备库可能要分担一些读请求，压力较大

4.长事务，导致备库重放时间过长

5.大表的DDL

# 网络

- 长连接如何实现？

HTTP长连接`keep-alive`，实际上是TCP的长连接，通过TCP的保活机制，服务端不断发送心跳包

长连接的好处是一个多个HTTP可以`复用`一个TCP连接

# 中间件

- rabbitmq能处理的最大消息长度？

通常是`4M`

- rabbitmq的最大qps？

在`万级别`

# 分布式

- 雪花算法？

一种生成分布式唯一ID的算法，生成的ID从左到右：`一位无效位，时间戳，工作器ID，序列号`

# 场景题

## feed流

- 有户分为有效用户和无效用户

- 数据拆分：索引和实际内容分开（做成K-V形式），索引的查询性能高，K-V易于扩展

- 异步发送，后台消息队列处理

- 服务拆分

- 经常访问的内容本地缓存

- 流量限制，保证可用性

- 异地分布，CDN

- `在线推，离线拉`
